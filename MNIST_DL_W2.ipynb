{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8sMApGOW7jy"
   },
   "source": [
    "Import MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r4IgANbqW7j0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Dzv7DUZX71M",
    "outputId": "eb4c4b2e-4da0-4b73-f318-1eecce61e5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000,)\n",
      "<class 'numpy.ndarray'> (60000, 10)\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "image, y_train = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='train',\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,\n",
    "))\n",
    "\n",
    "x_train=image.reshape(60000,-1)\n",
    "print(type(y_train), y_train.shape)\n",
    "enc = OneHotEncoder()\n",
    "y_train=y_train.reshape(-1, 1)\n",
    "enc.fit(y_train)\n",
    "y_train=enc.transform(y_train).toarray()\n",
    "print(type(y_train), y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wC5RVTTPaohZ"
   },
   "outputs": [],
   "source": [
    "image, y_test = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='test',\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,\n",
    "))\n",
    "\n",
    "x_test=image.reshape(10000,-1)\n",
    "enc = OneHotEncoder()\n",
    "y_test=y_test.reshape(-1, 1)\n",
    "enc.fit(y_test)\n",
    "y_test=enc.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2FnBeFJW7j-"
   },
   "source": [
    "Define the training data placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TF89U47eW7kA"
   },
   "outputs": [],
   "source": [
    "# Python optimization variables\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Declare the training data placeholders\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# Input x - for 28 x 28 pixels = 784\n",
    "x = tf.compat.v1.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
    "# Now declare the output data placeholder - 10 digits\n",
    "y = tf.compat.v1.placeholder(tf.float32, shape=[None, 10], name=\"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkTYk11MW7kE"
   },
   "source": [
    "Define the weights and the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u_G28CqLW7kF"
   },
   "outputs": [],
   "source": [
    "# Now declare the weights connecting the input to the hidden layer (300 neurons)\n",
    "W1 = tf.Variable(name=\"Weight1\", dtype=tf.float32, shape=[784, 300], initial_value=tf.random.normal(mean=0.0, stddev=0.01, shape=[784, 300], seed=42))\n",
    "b1 = tf.Variable(name=\"Bias1\", dtype=tf.float32, initial_value=tf.constant(0., shape=[300], dtype=tf.float32))\n",
    "# And the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(name=\"Weight2\", dtype=tf.float32, shape=[300, 10], initial_value=tf.random.normal(mean=0.0, stddev=0.01,shape=[300, 10], seed=42))\n",
    "b2 = tf.Variable(name=\"Bias2\", dtype=tf.float32, initial_value=tf.constant(0., shape=[10], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW8DUNrLW7kI"
   },
   "source": [
    "Calculate the output of the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vkiJ48P3W7kK"
   },
   "outputs": [],
   "source": [
    "# Calculate the output of the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.sigmoid(hidden_out)\n",
    "# Now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "# output layer\n",
    "out = tf.add(tf.matmul(hidden_out, W2), b2)\n",
    "y_ = tf.nn.softmax(out, name=\"Softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNLtNy-OW7kP"
   },
   "source": [
    "Generate cost and optimizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FMKexs2SW7kQ"
   },
   "outputs": [],
   "source": [
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = tf.reduce_mean(-tf.compat.v1.reduce_sum(y*tf.math.log(y_clipped),  reduction_indices=1))\n",
    "# Add an optimizer\n",
    "optimiser = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDWCINFHW7kT"
   },
   "source": [
    "Generate the assessment operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u7o69jpIW7kU"
   },
   "outputs": [],
   "source": [
    "# Finally setup the initialisation operator\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# Define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "johlhHl7W7kX"
   },
   "source": [
    "Start the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyCVgAMhW7kX",
    "outputId": "524fccf9-7947-4115-e007-f90e80bfc602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "Epoch: 01 cost= 1.7231359573205296\n",
      "Epoch: 02 cost= 1.2085440780719123\n",
      "Epoch: 03 cost= 1.2555728024244315\n",
      "Epoch: 04 cost= 1.2178202414512638\n",
      "Epoch: 05 cost= 1.1141365026434267\n",
      "Epoch: 06 cost= 1.0620982194940265\n",
      "Epoch: 07 cost= 1.1417118513584135\n",
      "Epoch: 08 cost= 1.0659333325425782\n",
      "Epoch: 09 cost= 1.1525953752795857\n",
      "Epoch: 10 cost= 1.1258779074748346\n",
      "Optimization Finished!\n",
      "Accuracy: 0.6651\n"
     ]
    }
   ],
   "source": [
    "# Start the session\n",
    "with tf.compat.v1.Session() as sess:\n",
    "  # Initialise the variables\n",
    "  sess.run(init_op)\n",
    "    \n",
    "  total_batch = int(x_train.shape[0]/batch_size)\n",
    "  print(total_batch)\n",
    "\n",
    "  # Training cycle \n",
    "  for i in range(epochs):\n",
    "    avg_cost = 0.\n",
    "    # Loop over all batches\n",
    "    for j in range(total_batch):\n",
    "      x_batch=x_train[j*batch_size:(j+1)*batch_size]\n",
    "      y_batch=y_train[j*batch_size:(j+1)*batch_size]\n",
    "      _, c = sess.run([optimiser, cross_entropy], feed_dict={x: x_batch, y: y_batch})\n",
    "      # Compute average loss\n",
    "      avg_cost += c / total_batch\n",
    "      \n",
    "    print (\"Epoch:\", '%02d' % (i+1), \"cost=\", \"{}\".format(avg_cost))\n",
    "\n",
    "  print (\"Optimization Finished!\")\n",
    "  # Test model\n",
    "  # Calculate accuracy for all examples\n",
    "  print (\"Accuracy:\", accuracy.eval({x: x_test, y: y_test}))  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TensorFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
